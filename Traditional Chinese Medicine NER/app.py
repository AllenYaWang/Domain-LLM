import gradio as gr
import torch
import json
import re
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel

# --- é…ç½®ä¸åŠ è½½æ¨¡å‹ ---
base_model_id = "models/Qwen/Qwen2.5-7B"  # è¯·æ›¿æ¢ä¸ºä½ æœ¬åœ°æ¨¡å‹çš„è·¯å¾„æˆ–HuggingFace ID
adapter_path = "./models/Qwen/qwen2.5-ner-sft"

tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
torch_dtype = torch.float16 if device in ["cuda", "mps"] else torch.float32

base_model = AutoModelForCausalLM.from_pretrained(
    base_model_id, 
    device_map=device, 
    dtype=torch_dtype, 
    trust_remote_code=True
)
model = PeftModel.from_pretrained(base_model, adapter_path)
model.eval()

# åŒevaluationä¸­çš„jsonæå–é€»è¾‘
def extract_json_list(text):
    text = text.replace("```json", "").replace("```", "").strip()
    
    start_idx = text.find('[')
    if start_idx == -1:
        return []

    balance = 0
    end_idx = -1
    for i in range(start_idx, len(text)):
        if text[i] == '[':
            balance += 1
        elif text[i] == ']':
            balance -= 1
        if balance == 0:
            end_idx = i
            break

    if end_idx == -1:
        return []

    json_str = text[start_idx : end_idx + 1]
    
    try:
        # å°è¯•è§£æå¹¶éªŒè¯ç±»å‹
        result = json.loads(json_str)
        if isinstance(result, list):
            return result
        return []
    except json.JSONDecodeError:
        return []
    except Exception:
        return []

def ner_predict(text):
    system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸­åŒ»è¯é¢†åŸŸçš„å‘½åå®ä½“è¯†åˆ«ä¸“å®¶ã€‚è¯·ä»ç»™å®šçš„æ–‡æœ¬ä¸­æå–å‡ºæ‰€æœ‰ä¸­åŒ»è¯ç›¸å…³çš„å®ä½“ï¼Œå¹¶ä»¥JSONåˆ—è¡¨æ ¼å¼è¾“å‡ºã€‚å®ä½“ç±»åˆ«åŒ…æ‹¬ï¼šä¸´åºŠè¡¨ç°ã€è¥¿åŒ»è¯Šæ–­ã€ä¸­åŒ»æ²»ç–—ã€æ–¹å‰‚ã€ä¸­è¯ã€ä¸­åŒ»è¯Šæ–­ã€è¥¿åŒ»æ²»ç–—ã€ä¸­åŒ»è¯å€™ã€ä¸­åŒ»æ²»åˆ™ã€å…¶ä»–æ²»ç–—ã€‚"
    instruction = f"è¯·æ‰¾å‡ºä»¥ä¸‹å¥å­ä¸­çš„ä¸­åŒ»è¯å®ä½“ï¼š\n{text}"
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": instruction}
    ]
    input_ids = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    model_inputs = tokenizer([input_ids], return_tensors="pt").to(model.device)
    
    with torch.no_grad():
        generated_ids = model.generate(
            **model_inputs, 
            max_new_tokens=512,
            temperature=0.1
        )
    
    generated_ids = [
        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
    ]
    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
    
    entities = extract_json_list(response) 
    
    if not entities:
        # å¦‚æœè§£æå¤±è´¥æˆ–ä¸ºç©ºï¼Œè¿”å›é”™è¯¯ä¿¡æ¯å’Œç©º JSON å­—ç¬¦ä¸²
        json_output_str = "[]"
        formatted = f"**æœªè¯†åˆ«åˆ°å®ä½“æˆ–è§£æå¤±è´¥ã€‚**\n\nè¯·æ£€æŸ¥æ¨¡å‹åŸå§‹è¾“å‡ºï¼Œå¯èƒ½å­˜åœ¨æ ¼å¼é—®é¢˜ã€‚\n\n**æ¨¡å‹åŸå§‹è¾“å‡ºï¼š**\n`{response.strip()}`"
    else:
        # æˆåŠŸè§£æï¼Œæ ¼å¼åŒ–å±•ç¤º
        formatted = "### è¯†åˆ«ç»“æœï¼š\n"
        grouped = {}
        for item in entities:
            etype = item.get('type', 'æœªçŸ¥')
            if etype not in grouped: grouped[etype] = []
            grouped[etype].append(item.get('entity', ''))
            
        for etype, names in grouped.items():
            formatted += f"**{etype}**: {', '.join(names)}\n"
            
        json_output_str = json.dumps(entities, ensure_ascii=False, indent=2)

    return formatted, json_output_str

# --- webç•Œé¢å¸ƒç½® ---
with gr.Blocks(title="ä¸­åŒ»è¯NERå¤§æ¨¡å‹") as demo:
    gr.Markdown("# ğŸ¥ ä¸­åŒ»è¯å‘½åå®ä½“è¯†åˆ«ç³»ç»Ÿ")
    with gr.Row():
        inp = gr.Textbox(label="è¾“å…¥æ–‡æœ¬", lines=8)
        btn = gr.Button("ğŸš€ å¼€å§‹è¯†åˆ«", variant="primary")
    with gr.Row():
        out_txt = gr.Markdown(label="è§£æç»“æœ")
        out_json = gr.JSON(label="åŸå§‹ JSON è¾“å‡º")
        
    btn.click(fn=ner_predict, inputs=inp, outputs=[out_txt, out_json])
    
    gr.Examples(
        examples=[
            ["æ‚£è€…ç´ æœ‰æ…¢æ€§èƒƒç‚ç—…å²ï¼Œæ­¤æ¬¡å› é¥®é£Ÿä¸èŠ‚å‡ºç°èƒƒè„˜èƒ€ç—›ï¼Œå—³æ°”åé…¸ï¼ŒèˆŒçº¢è‹”é»„è…»ï¼Œè„‰æ»‘æ•°ã€‚ä¸­åŒ»è¯Šæ–­ä¸ºèƒƒç—›ï¼Œè¯å±è‚èƒƒéƒçƒ­ã€‚"],
        ],
        inputs=inp
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0")
